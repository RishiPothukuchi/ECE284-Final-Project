{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"vgg_quant_ProjectPart1\"\n",
    "model = VGG16_quant()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Load your saved model and validate\n",
    "#  2. Replace your model's all the Conv's weight with quantized weight\n",
    "#  3. Apply reasonable alpha\n",
    "#  4. Then, try to multiple bit precisions and draw graph of bit precision vs. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9035/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/ProjectPart1Model/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "41 -th layer prehooked\n",
      "46 -th layer prehooked\n",
      "50 -th layer prehooked\n",
      "54 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1484., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "weight_q = model.features[27].weight_q\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "w_delta = w_alpha/((2**(w_bit-1)-1))\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "#print(weight_int)\n",
    "print(weight_int.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24156., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "act = save_output.outputs[8][0]\n",
    "act_alpha = model.features[27].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "act_delta = act_alpha/((2**act_bit)-1)\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "#print(act_int)\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "print(act_int.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "victorian-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.Parameter(weight_int)\n",
    "conv_int.bias = model.features[27].bias #type(model.features[3].bias) = NoneType\n",
    "output_int = conv_int(act_int)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
    "#print(output_recovered)\n",
    "#print(output_recovered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ref = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_ref.weight = model.features[27].weight_q\n",
    "conv_ref.bias = model.features[27].bias #type(model.features[3].bias) = NoneType\n",
    "output_ref = conv_ref(act)\n",
    "#print(output_ref)\n",
    "#print(output_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subsequent-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# act_int.size = torch.Size([128, 8, 4, 4]) <- batch_size, input_ch, ni, nj\n",
    "a_int = act_int[0,:,:,:] # pick only one input out of batch\n",
    "# act_int.size() = torch.Size([128, 8, 4, 4])\n",
    "# a_int.size() = [8, 4, 4]\n",
    "# conv_int.weight.size() = torch.Size([8, 8, 3, 3]) <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1),-1))\n",
    "# merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "######## Inputs ########\n",
    "nig = range(a_int.size(1)) ## ni group [0,1,...31]\n",
    "njg = range(a_int.size(2)) ## nj group\n",
    "nijg = range(a_int.size(1)*a_int.size(2))\n",
    "######## Weights and related stuff ########\n",
    "kijg = range(w_int.size(2)) # [0, .. 8]\n",
    "ki_dim = int(math.sqrt(w_int.size(2))) ## Kernel's 1 dim size = 3\n",
    "kig = range(int(math.sqrt(len(kijg)))) ## = 3\n",
    "kjg = range(int(math.sqrt(len(kijg)))) ## = 3\n",
    "######## Channels ########\n",
    "icg = range(int(w_int.size(1))) ## input channel [0,...7]\n",
    "ocg = range(int(w_int.size(0))) ## output channel [0,...7]\n",
    "ic_tileg = range(int(len(icg)/array_size)) ##[0]\n",
    "oc_tileg = range(int(len(ocg)/array_size)) ##[0]\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(njg)+padding*2).cuda()\n",
    "# a_pad.size() = [8, 4+2pad, 4+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0),-1)) ## merge ni and nj index into nij\n",
    "# a_pad.size() = [8, (4+2pad)*(4+2pad)]\n",
    "a_tile = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, a_pad.size(1)).cuda()\n",
    "for ic_tile in ic_tileg: #spatial\n",
    "    for oc_tile in oc_tileg: #spatial\n",
    "        a_tile[ic_tile,oc_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
    "p_nijg = range(a_tile.size(3)) ## paded activation's nij group [0, ...34*34-1]\n",
    "\n",
    "######## Outputs ########\n",
    "o_nig = range(int((math.sqrt(len(nijg))+2*padding-(math.sqrt(len(kijg))- 1)- 1)/stride + 1)) #range(0, 32)\n",
    "o_njg = range(int((math.sqrt(len(nijg))+2*padding-(math.sqrt(len(kijg))- 1)- 1)/stride + 1)) #range(0, 32)\n",
    "psum=torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda()\n",
    "out = torch.zeros(len(ocg), len(o_nig), len(o_njg)).cuda()\n",
    "######## Tiled 2D version ########\n",
    "for ic_tile in ic_tileg: #spatial\n",
    "    for oc_tile in oc_tileg: #spatial\n",
    "        for kij in kijg: #temporal\n",
    "            m = nn.Linear(array_size, array_size, bias=False)\n",
    "            m.weight = torch.nn.Parameter(w_int[oc_tile*array_size: (oc_tile+1)*array_size,ic_tile*array_size:(ic_tile+1)*array_size,kij])\n",
    "            for nij in p_nijg: #temporal\n",
    "                psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,oc_tile,:, nij]).cuda()\n",
    "\n",
    "### SFP accumulation ###\n",
    "for ni in o_nig:\n",
    "    for nj in o_njg:\n",
    "        for ki in kig:\n",
    "            for kj in kjg:\n",
    "                for ic_tile in ic_tileg:\n",
    "                    for oc_tile in oc_tileg:\n",
    "                        out[oc_tile*array_size:(oc_tile+1)*array_size, ni, nj] = out[oc_tile*array_size:(oc_tile+1)*array_size, ni, nj] + \\\n",
    "                        psum[ic_tile, oc_tile, :, int(math.sqrt(len(p_nijg)))*(ni+ki) + (nj+kj), len(kig)*ki+kj]\n",
    "out_relu = out.clone()\n",
    "\n",
    "### RELU ###\n",
    "for ni in range(out.size()[1]):\n",
    "    for nj in range(out.size()[2]):\n",
    "        for oc in range(out.size()[0]):\n",
    "            out_relu[oc,ni,nj]=out[oc,ni,nj]*(round(out[oc,ni,nj].item())>0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4930e-05, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This cell shows how recovered output has low error as compared to actual output\n",
    "(save_output.outputs[9][0][0]- out_relu.mul(act_delta).mul(w_delta)).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "ic_tile_id = 0\n",
    "oc_tile_id = 0\n",
    "#nij = 200 # just a random number\n",
    "X = a_tile[ic_tile_id,oc_tile_id,:,:] # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('activation_tile0.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)): # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[array_size-j-1,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])\n",
    "        #file.write(' ') # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "#w_int\n",
    "bit_precision = 4\n",
    "\n",
    "for kij in range(w_int.size(2)): # kij\n",
    "    file_name = \"weight_itile0_otile0_kij{}.txt\".format(kij)\n",
    "    file = open(file_name, 'w') #write to file\n",
    "    file.write('#ic7oc0[msb-lsb],ic6oc0[msb-lst],....,ic0oc0[msb-lst]#\\n')\n",
    "    file.write('#ic7oc1[msb-lsb],ic6oc1[msb-lst],....,ic0oc1[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    for oc in range(w_int.size(0)): # output channel\n",
    "        for ic in range(w_int.size(1)): # input channel\n",
    "            w_int_bin = '{0:04b}'.format(round(w_int[oc,array_size-ic-1,kij].item())+2**(bit_precision)*(round(w_int[oc,array_size-ic-1,kij].item())<0))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(w_int_bin[k])\n",
    "        file.write('\\n')\n",
    "        #file.write(' ') # for visibility with blank between words, you can use\n",
    "file.close() #close file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "#w_int\n",
    "bit_precision = 16\n",
    "file = open('out.txt', 'w') #write to file\n",
    "file.write('#oc0nij0[msb-lsb],oc1nij0[msb-lst],....,oc7nij0[msb-lst]#\\n')\n",
    "file.write('#oc0nij1[msb-lsb],oc1nij1[msb-lst],....,oc7nij1[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for ni in range(out.size(1)): # ni\n",
    "    for nj in range(out.size(2)): # nj\n",
    "        for oc in range(out.size(0)): # output channel\n",
    "            out_int_bin = '{0:016b}'.format(round(out[oc,ni,nj].item())+2**(bit_precision)*(round(out[oc,ni,nj].item())<0))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(out_int_bin[k])\n",
    "        file.write('\\n')\n",
    "#file.write(' ') # for visibility with blank between words, you can use\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### show this cell partially. The following cells should be printed by students ###\n",
    " #w_int\n",
    "bit_precision = 16\n",
    "file = open('out_relu.txt', 'w') #write to file\n",
    "file.write('#oc0nij0[msb-lsb],oc1nij0[msb-lst],....,oc7nij0[msb-lst]#\\n')\n",
    "file.write('#oc0nij1[msb-lsb],oc1nij1[msb-lst],....,oc7nij1[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for ni in range(out_relu.size(1)): # ni\n",
    "    for nj in range(out_relu.size(2)): # nj\n",
    "        for oc in range(out_relu.size(0)): # output channel\n",
    "            out_int_bin = '{0:016b}'.format(round(out_relu[oc,ni,nj].item())+2**(bit_precision)*(round(out_relu[oc,ni,nj].item())<0))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(out_int_bin[k])\n",
    "        file.write('\\n')\n",
    "#file.write(' ') # for visibility with blank between words, you can use\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c337da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc.txt generated with 144 addresses\n"
     ]
    }
   ],
   "source": [
    "len_kij   = 9      # number of kernel taps (kij = 0..8)\n",
    "len_onij  = 16     # number of output positions (4x4)\n",
    "addr_bits = 11     # width of PMEM address (A_pmem is 11 bits)\n",
    "\n",
    "with open(\"acc.txt\", \"w\") as f:\n",
    "    # Header lines (same style as before)\n",
    "    f.write(\"#acc0: addresses of psums to be accumulated per output window#\\n\")\n",
    "    f.write(\"#9 addresses (for kij 0..8) per (ni,nj) output position#\\n\")\n",
    "    f.write(\"#................#\\n\")\n",
    "\n",
    "    # For each output window index i (0..15)\n",
    "    for out_idx in range(len_onij):  # 0..15\n",
    "        # For each kij (0..8), compute pmem address = kij*16 + out_idx\n",
    "        for kij in range(len_kij):\n",
    "            addr = kij * len_onij + out_idx    # kij*16 + out_idx\n",
    "            addr_bin = format(addr, f\"0{addr_bits}b\")  # 11-bit binary\n",
    "            f.write(addr_bin + \"\\n\")\n",
    "\n",
    "file.close()\n",
    "print(\"acc.txt generated with\", (len(o_nig) * len(o_njg) * len(kig) * len(kjg)), \"addresses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "documentary-indication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(102665., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "act = save_output.outputs[9][0]\n",
    "act_alpha = model.features[27].act_alpha #maybe use previous layers act alpha only\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "#print(act_int)\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "print(act_int.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-institute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-taste",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-tribune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-procurement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
